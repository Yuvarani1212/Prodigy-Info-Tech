Hi there 👋

Welcome to my GitHub profile! I'm finished a Data Science intern at Prodigy Infobyte. 

I am passionate about extracting meaningful insights from data and using machine learning to solve real-world problems. 

Below you'll find some highlights of my projects and skills.

🧑‍💻 About Me

Name: Yuvarani S

Position: Data Science Intern at Prodigy Infobyte

Interests: Data Science, Machine Learning, Data Visualization

🛠️ Skills

Languages: Python

Libraries/Frameworks: pandas, NumPy, scikit-learn, TensorFlow, Keras, matplotlib, seaborn

Tools: Jupyter Notebook

Other Skills: Data cleaning, Data visualization, Statistical analysis, Machine learning

🌟 Featured Projects

TASK -1 : Distribution visualization

DESCRIPTION: This project involves creating a bar chart or histogram to visualize the distribution of a specific variable in a dataset.

The objective is to gain insights into the data by understanding the frequency and patterns of the variable's values.

📍FEATURES:

●Data collection and preprocessing

●Creation of a bar chart for categorical data

●Creation of a histogram for continuous data

●Customization of visualizations for clarity and aesthetics

●Interpretation of the distribution patterns to derive meaningful insights

●Technologies: Python, pandas, matplotlib, seaborn, Jupyter Notebook

                                                                                   📍Here's a detailed breakdown:

📍Data Collection: Gather a dataset that includes the variable of interest.

📍Data Preprocessing: Clean the data to handle missing values and ensure consistent formatting.

📍Distribution Visualization:

📍For Categorical Variable:

📍Objective: Visualize the distribution of a categorical variable, such as gender.

📍Method: Use a bar chart to display the count or frequency of each category.

📍For Continuous Variable:

📍Objective: Visualize the distribution of a continuous variable, such as age.

📍Method: Use a histogram to display the frequency distribution of different values.

📍Customization and Interpretation:

●Customize the visualizations by adding titles, labels, and adjusting aesthetics for better readability.

●Interpret the visualizations to understand the distribution patterns and derive insights, 

such as identifying common categories in a bar chart or typical value ranges in a histogram.

TASK-2: Data Cleaning and Exploratory Data Analysis (EDA) on Titanic Dataset

📍Description: This project involves performing data cleaning and exploratory data analysis (EDA) on the Titanic dataset from chatgpt.

The goal is to preprocess the data, explore relationships between variables, and identify patterns and trends that could provide insights into the factors influencing survival rates on the Titanic.

📍FEATURES:

📍Data Cleaning:

●Handling missing values in columns such as age, cabin, and embarked.

●For instance, missing ages might be filled with the median age, while missing embarkation points could be filled with the most frequent value.

●Converting categorical variables (like gender and embarkation port) into numerical formats for analysis.

●Detecting and addressing outliers that could skew the analysis.

📍Exploratory Data Analysis (EDA):

●Understanding the distribution of key variables such as age, fare, and class.

📍Exploring relationships between different variables:

●Age and Survival Rate: Analyzing if younger passengers had a higher survival rate compared to older passengers.

●Class and Survival Rate: Investigating if passengers in higher classes (first class) had better chances of survival compared to those in lower classes (third class).

●Sex and Survival Rate: Examining the survival rate differences between male and female passengers.

📍Visualizing the data using various types of plots:

📍Histograms: To show the distribution of continuous variables like age and fare.

📍Bar Charts: To depict the survival rates by class and gender.

📍Box Plots: To identify the spread and potential outliers in fare prices across different classes.

📍Scatter Plots: To explore the relationship between age and fare, and how they relate to survival.

📍Statistical Analysis:

●Conducting statistical tests to determine if the observed relationships between variables are significant.

●This helps in confirming whether factors like age, class, and sex significantly influenced survival rates.

●Using correlation analysis to identify the strength and direction of relationships between variables. 

●For instance, checking if there's a strong negative correlation between class and survival rate.

●summary of Findings:

📍Summarizing the key insights derived from the EDA.

●This includes highlighting the significant factors influencing survival rates and presenting the findings through well-designed visualizations.

●For example, one might find that women and children had higher survival rates, and that passengers in first class had better chances of survival compared to those in third class.

TASK 4 : Sentiment Analysis and Visualization of Social Media Data
 
📍Description: 

●This project involves analyzing and visualizing sentiment patterns in social media data to understand public opinion and attitudes towards specific topics or brands.

●By leveraging sentiment analysis techniques, we can extract and quantify the emotions expressed in social media posts, providing valuable insights into public perception.

📍Features:

📍Data Collection:

●Gather social media data related to specific topics or brands using APIs provided by platforms like Twitter, Facebook, or Instagram.

●Fetch posts, tweets, comments, or reviews that mention the targeted topics or brands.

📍Data Preprocessing:

●Clean the data to remove noise such as URLs, hashtags, mentions, and special characters.

●Tokenize the text data to break it down into individual words or phrases.

●Normalize the data by converting text to lowercase and handling contractions.

📍Sentiment Analysis:

●Apply sentiment analysis techniques to classify the sentiment expressed in each post. This can be done using pre-trained models or libraries like VADER, TextBlob, or transformers like BERT.

●Classify sentiments into categories such as positive, negative, and neutral, or use a sentiment score to quantify the intensity of the sentiment.

📍Exploratory Data Analysis (EDA):

●Analyze the distribution of sentiments across the dataset to understand the overall sentiment trend.

●Identify key themes and topics associated with different sentiment categories.

●Explore temporal patterns to see how sentiment changes over time.

📍Visualization:

●Use various visualizations to present the sentiment analysis results:

📍Bar Charts: Show the count or percentage of posts in each sentiment category.

📍Word Clouds: Highlight the most common words or phrases associated with positive, negative, and neutral sentiments.

📍Time Series Plots: Visualize sentiment trends over time, identifying peaks and troughs in public opinion.

📍Heatmaps: Display the correlation between different sentiment categories and specific topics or keywords.

📍Geographical Maps: Show the geographical distribution of sentiments if location data is available.

📍Insights and Interpretation:

●Summarize the key findings from the sentiment analysis.

●Identify patterns and trends that indicate public opinion towards the topics or brands.

●Provide actionable insights for stakeholders, such as identifying potential areas for improvement or highlighting positive aspects that resonate with the audience.

📍TECHNOLOGIES: Python, pandas, NumPy, NLTK, TextBlob, VADER, transformers (BERT), matplotlib, seaborn, Plotly, Geopandas

TASK 5:Traffic Accident Data Analysis and Visualization

📍DESCRIPTION:
●This project involves analyzing traffic accident data to identify patterns related to road conditions, weather, and time of day.

●The goal is to uncover insights into the factors contributing to accidents and visualize accident hotspots. 

●This analysis can help in developing strategies to improve road safety and reduce accident rates.

📍FEATURES:

📍Data Collection:

●Gather traffic accident data from sources such as government databases, transportation departments, or public datasets.

●The data should include information on the location, time, weather conditions, road conditions, and details of each accident.

📍Data Preprocessing:

●Clean the data to handle missing values, incorrect entries, and inconsistent formats.

●Convert categorical data into numerical formats if necessary, and create new features if needed (e.g., categorizing times of day into morning, afternoon, evening, night).

📍Exploratory Data Analysis (EDA):

●Analyze the distribution of accidents across different times of day, weather conditions, and road conditions.

●Identify correlations between these factors and the frequency or severity of accidents.

●Explore the spatial distribution of accidents to identify hotspots.

📍Visualization:

●Use various visualization techniques to present the analysis results:

●Heatmaps: Display accident hotspots on a map to show the geographical concentration of accidents.

●Bar Charts: Show the distribution of accidents by time of day, weather conditions, and road conditions.

●Scatter Plots: Visualize the relationship between weather conditions and the number of accidents.

●Line Charts: Illustrate trends in accident occurrences over different periods (e.g., hourly, daily, monthly).

📍Insights and Interpretation:

●Summarize key findings from the analysis, highlighting significant patterns and contributing factors to traffic accidents.

●Provide actionable insights and recommendations for improving road safety, such as identifying high-risk times and conditions, and suggesting preventive measures.

📍TECHNOLOGIES: Python, pandas, NumPy, matplotlib, seaborn, Plotly, Folium (for geographical maps), Jupyter Notebook

📫 Connect with Me

Email: yuvaranisaravanan1212@gmail.com

LinkedIn: https://www.linkedin.com/in/yuvarani-saravanan-a809ba27b/recent-activity/all/




